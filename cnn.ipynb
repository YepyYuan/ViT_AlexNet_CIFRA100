{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR100(\"./data\", train=True, \n",
    "                                     transform=train_transform,download=True)\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR100(\"./data\", train=False, \n",
    "                                     transform=test_transform,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNCifar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNCifar,self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "        nn.Conv2d(3,64,3,padding=2),   nn.BatchNorm2d(64),  nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "        nn.Conv2d(64,128,3,padding=2), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "        nn.Conv2d(128,256,3,padding=1),nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "        nn.Conv2d(256,512,3,padding=1),nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.classifier=nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(2048, 4096),nn.ReLU(),nn.Dropout(0.5),\n",
    "        nn.Linear(4096,4096), nn.ReLU(),nn.Dropout(0.5),\n",
    "        nn.Linear(4096,100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.feature(x)\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoches = 200\n",
    "batchsize = 16\n",
    "lr = 0.001\n",
    "\n",
    "model = CNNCifar()\n",
    "model = model.to(device)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 4.043055 acc: 0.079\n",
      "test loss: 3.612433 acc: 0.137\n",
      "Epoch 2| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 3.475332 acc: 0.159\n",
      "test loss: 3.115254 acc: 0.227\n",
      "Epoch 3| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 3.148808 acc: 0.217\n",
      "test loss: 2.851669 acc: 0.280\n",
      "Epoch 4| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.924604 acc: 0.262\n",
      "test loss: 2.631538 acc: 0.322\n",
      "Epoch 5| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.749338 acc: 0.294\n",
      "test loss: 2.445328 acc: 0.359\n",
      "Epoch 6| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.607977 acc: 0.322\n",
      "test loss: 2.291287 acc: 0.393\n",
      "Epoch 7| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.484952 acc: 0.351\n",
      "test loss: 2.257736 acc: 0.406\n",
      "Epoch 8| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.377463 acc: 0.377\n",
      "test loss: 2.129812 acc: 0.434\n",
      "Epoch 9| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.279805 acc: 0.397\n",
      "test loss: 2.073800 acc: 0.444\n",
      "Epoch 10| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.216727 acc: 0.410\n",
      "test loss: 1.963088 acc: 0.471\n",
      "Epoch 11| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.141313 acc: 0.424\n",
      "test loss: 1.965658 acc: 0.468\n",
      "Epoch 12| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.074127 acc: 0.440\n",
      "test loss: 1.871145 acc: 0.495\n",
      "Epoch 13| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 2.012892 acc: 0.454\n",
      "test loss: 1.850394 acc: 0.495\n",
      "Epoch 14| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.960103 acc: 0.466\n",
      "test loss: 1.815071 acc: 0.512\n",
      "Epoch 15| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.914830 acc: 0.477\n",
      "test loss: 1.777832 acc: 0.516\n",
      "Epoch 16| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.865877 acc: 0.490\n",
      "test loss: 1.741744 acc: 0.522\n",
      "Epoch 17| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.830019 acc: 0.498\n",
      "test loss: 1.717011 acc: 0.532\n",
      "Epoch 18| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.783896 acc: 0.507\n",
      "test loss: 1.671194 acc: 0.538\n",
      "Epoch 19| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.746472 acc: 0.516\n",
      "test loss: 1.642861 acc: 0.551\n",
      "Epoch 20| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.710121 acc: 0.528\n",
      "test loss: 1.633181 acc: 0.550\n",
      "Epoch 21| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.678526 acc: 0.533\n",
      "test loss: 1.642517 acc: 0.546\n",
      "Epoch 22| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.646572 acc: 0.541\n",
      "test loss: 1.613477 acc: 0.557\n",
      "Epoch 23| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.613523 acc: 0.549\n",
      "test loss: 1.581374 acc: 0.560\n",
      "Epoch 24| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.578390 acc: 0.554\n",
      "test loss: 1.545485 acc: 0.576\n",
      "Epoch 25| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.554521 acc: 0.563\n",
      "test loss: 1.546556 acc: 0.571\n",
      "Epoch 26| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.528356 acc: 0.568\n",
      "test loss: 1.539338 acc: 0.572\n",
      "Epoch 27| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.495082 acc: 0.576\n",
      "test loss: 1.511927 acc: 0.581\n",
      "Epoch 28| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.467453 acc: 0.582\n",
      "test loss: 1.508071 acc: 0.586\n",
      "Epoch 29| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.441712 acc: 0.590\n",
      "test loss: 1.538653 acc: 0.579\n",
      "Epoch 30| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.419701 acc: 0.597\n",
      "test loss: 1.458996 acc: 0.598\n",
      "Epoch 31| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.389859 acc: 0.600\n",
      "test loss: 1.463895 acc: 0.594\n",
      "Epoch 32| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.376660 acc: 0.604\n",
      "test loss: 1.473978 acc: 0.592\n",
      "Epoch 33| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.352070 acc: 0.612\n",
      "test loss: 1.457103 acc: 0.597\n",
      "Epoch 34| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.336207 acc: 0.613\n",
      "test loss: 1.442117 acc: 0.600\n",
      "Epoch 35| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.302734 acc: 0.624\n",
      "test loss: 1.425578 acc: 0.607\n",
      "Epoch 36| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.286226 acc: 0.628\n",
      "test loss: 1.453858 acc: 0.599\n",
      "Epoch 37| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.266458 acc: 0.633\n",
      "test loss: 1.455402 acc: 0.600\n",
      "Epoch 38| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.244364 acc: 0.638\n",
      "test loss: 1.415809 acc: 0.609\n",
      "Epoch 39| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.223637 acc: 0.643\n",
      "test loss: 1.399333 acc: 0.616\n",
      "Epoch 40| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.206371 acc: 0.647\n",
      "test loss: 1.396838 acc: 0.613\n",
      "Epoch 41| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.187272 acc: 0.652\n",
      "test loss: 1.396022 acc: 0.617\n",
      "Epoch 42| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.169257 acc: 0.655\n",
      "test loss: 1.420544 acc: 0.613\n",
      "Epoch 43| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.148054 acc: 0.662\n",
      "test loss: 1.384564 acc: 0.620\n",
      "Epoch 44| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.134472 acc: 0.665\n",
      "test loss: 1.379416 acc: 0.623\n",
      "Epoch 45| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.110817 acc: 0.672\n",
      "test loss: 1.393018 acc: 0.620\n",
      "Epoch 46| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.099362 acc: 0.675\n",
      "test loss: 1.361579 acc: 0.623\n",
      "Epoch 47| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.086301 acc: 0.677\n",
      "test loss: 1.375205 acc: 0.621\n",
      "Epoch 48| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.068461 acc: 0.681\n",
      "test loss: 1.358674 acc: 0.628\n",
      "Epoch 49| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.046292 acc: 0.689\n",
      "test loss: 1.365813 acc: 0.632\n",
      "Epoch 50| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.030384 acc: 0.691\n",
      "test loss: 1.356840 acc: 0.629\n",
      "Epoch 51| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 1.017478 acc: 0.696\n",
      "test loss: 1.347841 acc: 0.629\n",
      "Epoch 52| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.995657 acc: 0.700\n",
      "test loss: 1.346854 acc: 0.631\n",
      "Epoch 53| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.990482 acc: 0.702\n",
      "test loss: 1.357684 acc: 0.630\n",
      "Epoch 54| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.973141 acc: 0.707\n",
      "test loss: 1.345397 acc: 0.631\n",
      "Epoch 55| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.958591 acc: 0.713\n",
      "test loss: 1.345025 acc: 0.637\n",
      "Epoch 56| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.936880 acc: 0.717\n",
      "test loss: 1.354229 acc: 0.632\n",
      "Epoch 57| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.927633 acc: 0.721\n",
      "test loss: 1.337207 acc: 0.637\n",
      "Epoch 58| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.915351 acc: 0.724\n",
      "test loss: 1.357559 acc: 0.634\n",
      "Epoch 59| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.903008 acc: 0.729\n",
      "test loss: 1.335081 acc: 0.641\n",
      "Epoch 60| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.888249 acc: 0.730\n",
      "test loss: 1.360986 acc: 0.636\n",
      "Epoch 61| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.871789 acc: 0.734\n",
      "test loss: 1.351563 acc: 0.638\n",
      "Epoch 62| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.861680 acc: 0.737\n",
      "test loss: 1.342178 acc: 0.642\n",
      "Epoch 63| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.847314 acc: 0.742\n",
      "test loss: 1.355224 acc: 0.637\n",
      "Epoch 64| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.842043 acc: 0.742\n",
      "test loss: 1.330867 acc: 0.644\n",
      "Epoch 65| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.813338 acc: 0.749\n",
      "test loss: 1.352140 acc: 0.642\n",
      "Epoch 66| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.809687 acc: 0.750\n",
      "test loss: 1.337522 acc: 0.646\n",
      "Epoch 67| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.802806 acc: 0.754\n",
      "test loss: 1.343998 acc: 0.640\n",
      "Epoch 68| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.790590 acc: 0.755\n",
      "test loss: 1.339266 acc: 0.647\n",
      "Epoch 69| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.770532 acc: 0.763\n",
      "test loss: 1.339118 acc: 0.644\n",
      "Epoch 70| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.765477 acc: 0.762\n",
      "test loss: 1.319765 acc: 0.648\n",
      "Epoch 71| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.747052 acc: 0.768\n",
      "test loss: 1.340446 acc: 0.644\n",
      "Epoch 72| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.732416 acc: 0.774\n",
      "test loss: 1.365613 acc: 0.646\n",
      "Epoch 73| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.729743 acc: 0.773\n",
      "test loss: 1.339861 acc: 0.648\n",
      "Epoch 74| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.721278 acc: 0.774\n",
      "test loss: 1.345388 acc: 0.646\n",
      "Epoch 75| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.710109 acc: 0.778\n",
      "test loss: 1.353353 acc: 0.639\n",
      "Epoch 76| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.699847 acc: 0.782\n",
      "test loss: 1.337443 acc: 0.651\n",
      "Epoch 77| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.677091 acc: 0.789\n",
      "test loss: 1.331316 acc: 0.655\n",
      "Epoch 78| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.674425 acc: 0.789\n",
      "test loss: 1.332588 acc: 0.653\n",
      "Epoch 79| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.659087 acc: 0.793\n",
      "test loss: 1.352109 acc: 0.651\n",
      "Epoch 80| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.663622 acc: 0.793\n",
      "test loss: 1.358412 acc: 0.650\n",
      "Epoch 81| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.647093 acc: 0.798\n",
      "test loss: 1.365559 acc: 0.651\n",
      "Epoch 82| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.640207 acc: 0.798\n",
      "test loss: 1.353792 acc: 0.656\n",
      "Epoch 83| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.631373 acc: 0.801\n",
      "test loss: 1.383489 acc: 0.649\n",
      "Epoch 84| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.618800 acc: 0.806\n",
      "test loss: 1.350766 acc: 0.651\n",
      "Epoch 85| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.609229 acc: 0.807\n",
      "test loss: 1.360160 acc: 0.652\n",
      "Epoch 86| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.606313 acc: 0.808\n",
      "test loss: 1.352364 acc: 0.654\n",
      "Epoch 87| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.590944 acc: 0.813\n",
      "test loss: 1.357815 acc: 0.654\n",
      "Epoch 88| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.580376 acc: 0.816\n",
      "test loss: 1.365474 acc: 0.660\n",
      "Epoch 89| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.574250 acc: 0.818\n",
      "test loss: 1.366367 acc: 0.657\n",
      "Epoch 90| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.569130 acc: 0.819\n",
      "test loss: 1.377396 acc: 0.651\n",
      "Epoch 91| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.567295 acc: 0.821\n",
      "test loss: 1.395955 acc: 0.653\n",
      "Epoch 92| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.550412 acc: 0.825\n",
      "test loss: 1.390745 acc: 0.652\n",
      "Epoch 93| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.542760 acc: 0.827\n",
      "test loss: 1.393707 acc: 0.657\n",
      "Epoch 94| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.531487 acc: 0.830\n",
      "test loss: 1.372711 acc: 0.652\n",
      "Epoch 95| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.528339 acc: 0.832\n",
      "test loss: 1.385070 acc: 0.658\n",
      "Epoch 96| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.515477 acc: 0.836\n",
      "test loss: 1.402352 acc: 0.657\n",
      "Epoch 97| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.509174 acc: 0.838\n",
      "test loss: 1.392357 acc: 0.661\n",
      "Epoch 98| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.504259 acc: 0.838\n",
      "test loss: 1.388553 acc: 0.657\n",
      "Epoch 99| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.500390 acc: 0.840\n",
      "test loss: 1.416048 acc: 0.660\n",
      "Epoch 100| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.489735 acc: 0.844\n",
      "test loss: 1.406393 acc: 0.658\n",
      "Epoch 101| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.476923 acc: 0.849\n",
      "test loss: 1.418944 acc: 0.655\n",
      "Epoch 102| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.476236 acc: 0.847\n",
      "test loss: 1.409453 acc: 0.659\n",
      "Epoch 103| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.460474 acc: 0.853\n",
      "test loss: 1.441618 acc: 0.656\n",
      "Epoch 104| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.464570 acc: 0.850\n",
      "test loss: 1.417799 acc: 0.660\n",
      "Epoch 105| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.459322 acc: 0.854\n",
      "test loss: 1.404011 acc: 0.660\n",
      "Epoch 106| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.446444 acc: 0.856\n",
      "test loss: 1.417588 acc: 0.661\n",
      "Epoch 107| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.441389 acc: 0.856\n",
      "test loss: 1.412312 acc: 0.659\n",
      "Epoch 108| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.444339 acc: 0.857\n",
      "test loss: 1.397146 acc: 0.664\n",
      "Epoch 109| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.432539 acc: 0.860\n",
      "test loss: 1.423906 acc: 0.663\n",
      "Epoch 110| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.428611 acc: 0.863\n",
      "test loss: 1.434833 acc: 0.659\n",
      "Epoch 111| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.418783 acc: 0.863\n",
      "test loss: 1.443163 acc: 0.659\n",
      "Epoch 112| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.414923 acc: 0.866\n",
      "test loss: 1.455158 acc: 0.656\n",
      "Epoch 113| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.400105 acc: 0.870\n",
      "test loss: 1.450147 acc: 0.661\n",
      "Epoch 114| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.403625 acc: 0.870\n",
      "test loss: 1.443114 acc: 0.660\n",
      "Epoch 115| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.403854 acc: 0.871\n",
      "test loss: 1.493134 acc: 0.658\n",
      "Epoch 116| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.389300 acc: 0.875\n",
      "test loss: 1.452617 acc: 0.665\n",
      "Epoch 117| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.390812 acc: 0.874\n",
      "test loss: 1.442080 acc: 0.657\n",
      "Epoch 118| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.383365 acc: 0.876\n",
      "test loss: 1.445449 acc: 0.661\n",
      "Epoch 119| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.378149 acc: 0.876\n",
      "test loss: 1.447700 acc: 0.662\n",
      "Epoch 120| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.376842 acc: 0.879\n",
      "test loss: 1.434311 acc: 0.660\n",
      "Epoch 121| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.370587 acc: 0.879\n",
      "test loss: 1.449487 acc: 0.662\n",
      "Epoch 122| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.361723 acc: 0.882\n",
      "test loss: 1.463173 acc: 0.659\n",
      "Epoch 123| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.353662 acc: 0.885\n",
      "test loss: 1.469246 acc: 0.665\n",
      "Epoch 124| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.353064 acc: 0.888\n",
      "test loss: 1.491123 acc: 0.661\n",
      "Epoch 125| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.347977 acc: 0.886\n",
      "test loss: 1.495128 acc: 0.658\n",
      "Epoch 126| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.342139 acc: 0.891\n",
      "test loss: 1.484396 acc: 0.659\n",
      "Epoch 127| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.338245 acc: 0.889\n",
      "test loss: 1.457402 acc: 0.667\n",
      "Epoch 128| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.341346 acc: 0.889\n",
      "test loss: 1.475750 acc: 0.662\n",
      "Epoch 129| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.337461 acc: 0.888\n",
      "test loss: 1.474203 acc: 0.659\n",
      "Epoch 130| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.326045 acc: 0.895\n",
      "test loss: 1.497794 acc: 0.664\n",
      "Epoch 131| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.328029 acc: 0.894\n",
      "test loss: 1.492221 acc: 0.664\n",
      "Epoch 132| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.321414 acc: 0.895\n",
      "test loss: 1.494399 acc: 0.663\n",
      "Epoch 133| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.313039 acc: 0.899\n",
      "test loss: 1.484592 acc: 0.663\n",
      "Epoch 134| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.316602 acc: 0.896\n",
      "test loss: 1.514403 acc: 0.658\n",
      "Epoch 135| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.306450 acc: 0.902\n",
      "test loss: 1.512767 acc: 0.664\n",
      "Epoch 136| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.305704 acc: 0.900\n",
      "test loss: 1.506941 acc: 0.665\n",
      "Epoch 137| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.301178 acc: 0.903\n",
      "test loss: 1.508685 acc: 0.664\n",
      "Epoch 138| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.302298 acc: 0.902\n",
      "test loss: 1.504054 acc: 0.665\n",
      "Epoch 139| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.297481 acc: 0.903\n",
      "test loss: 1.535270 acc: 0.660\n",
      "Epoch 140| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.295628 acc: 0.904\n",
      "test loss: 1.526618 acc: 0.663\n",
      "Epoch 141| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.285828 acc: 0.906\n",
      "test loss: 1.529739 acc: 0.664\n",
      "Epoch 142| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.283019 acc: 0.907\n",
      "test loss: 1.554769 acc: 0.659\n",
      "Epoch 143| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.290256 acc: 0.906\n",
      "test loss: 1.537438 acc: 0.661\n",
      "Epoch 144| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.287053 acc: 0.907\n",
      "test loss: 1.510748 acc: 0.668\n",
      "Epoch 145| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.278346 acc: 0.910\n",
      "test loss: 1.547992 acc: 0.663\n",
      "Epoch 146| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.273843 acc: 0.912\n",
      "test loss: 1.540100 acc: 0.659\n",
      "Epoch 147| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.270008 acc: 0.910\n",
      "test loss: 1.540963 acc: 0.658\n",
      "Epoch 148| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.265268 acc: 0.912\n",
      "test loss: 1.539940 acc: 0.660\n",
      "Epoch 149| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.267116 acc: 0.913\n",
      "test loss: 1.552818 acc: 0.662\n",
      "Epoch 150| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.259272 acc: 0.917\n",
      "test loss: 1.558283 acc: 0.665\n",
      "Epoch 151| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.262694 acc: 0.914\n",
      "test loss: 1.565707 acc: 0.660\n",
      "Epoch 152| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.260345 acc: 0.915\n",
      "test loss: 1.558250 acc: 0.665\n",
      "Epoch 153| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.259000 acc: 0.916\n",
      "test loss: 1.568459 acc: 0.664\n",
      "Epoch 154| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.251006 acc: 0.919\n",
      "test loss: 1.566023 acc: 0.667\n",
      "Epoch 155| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.254043 acc: 0.916\n",
      "test loss: 1.563827 acc: 0.664\n",
      "Epoch 156| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.247215 acc: 0.920\n",
      "test loss: 1.559276 acc: 0.664\n",
      "Epoch 157| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.235165 acc: 0.925\n",
      "test loss: 1.585455 acc: 0.665\n",
      "Epoch 158| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.245759 acc: 0.921\n",
      "test loss: 1.558059 acc: 0.662\n",
      "Epoch 159| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.238438 acc: 0.922\n",
      "test loss: 1.571738 acc: 0.665\n",
      "Epoch 160| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.235143 acc: 0.923\n",
      "test loss: 1.559484 acc: 0.670\n",
      "Epoch 161| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.237361 acc: 0.922\n",
      "test loss: 1.568054 acc: 0.667\n",
      "Epoch 162| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.227931 acc: 0.926\n",
      "test loss: 1.612987 acc: 0.664\n",
      "Epoch 163| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.225174 acc: 0.927\n",
      "test loss: 1.569921 acc: 0.665\n",
      "Epoch 164| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.225904 acc: 0.927\n",
      "test loss: 1.571321 acc: 0.665\n",
      "Epoch 165| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.222784 acc: 0.927\n",
      "test loss: 1.604248 acc: 0.666\n",
      "Epoch 166| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.220550 acc: 0.928\n",
      "test loss: 1.556342 acc: 0.667\n",
      "Epoch 167| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.214363 acc: 0.929\n",
      "test loss: 1.567088 acc: 0.664\n",
      "Epoch 168| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.216302 acc: 0.930\n",
      "test loss: 1.589060 acc: 0.666\n",
      "Epoch 169| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.215821 acc: 0.930\n",
      "test loss: 1.555072 acc: 0.662\n",
      "Epoch 170| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.213788 acc: 0.931\n",
      "test loss: 1.584296 acc: 0.665\n",
      "Epoch 171| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.209173 acc: 0.932\n",
      "test loss: 1.582749 acc: 0.665\n",
      "Epoch 172| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.210653 acc: 0.933\n",
      "test loss: 1.595560 acc: 0.664\n",
      "Epoch 173| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.209814 acc: 0.931\n",
      "test loss: 1.614971 acc: 0.661\n",
      "Epoch 174| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.210327 acc: 0.931\n",
      "test loss: 1.584526 acc: 0.664\n",
      "Epoch 175| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.206043 acc: 0.932\n",
      "test loss: 1.610147 acc: 0.663\n",
      "Epoch 176| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.207672 acc: 0.933\n",
      "test loss: 1.584216 acc: 0.668\n",
      "Epoch 177| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.197082 acc: 0.935\n",
      "test loss: 1.582261 acc: 0.666\n",
      "Epoch 178| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.199157 acc: 0.937\n",
      "test loss: 1.585545 acc: 0.670\n",
      "Epoch 179| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.198671 acc: 0.935\n",
      "test loss: 1.583864 acc: 0.663\n",
      "Epoch 180| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.196407 acc: 0.937\n",
      "test loss: 1.610008 acc: 0.671\n",
      "Epoch 181| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.196824 acc: 0.937\n",
      "test loss: 1.610665 acc: 0.668\n",
      "Epoch 182| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.190208 acc: 0.939\n",
      "test loss: 1.614269 acc: 0.665\n",
      "Epoch 183| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.190797 acc: 0.939\n",
      "test loss: 1.587939 acc: 0.666\n",
      "Epoch 184| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.192026 acc: 0.938\n",
      "test loss: 1.626673 acc: 0.668\n",
      "Epoch 185| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.189788 acc: 0.939\n",
      "test loss: 1.612230 acc: 0.668\n",
      "Epoch 186| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.190965 acc: 0.938\n",
      "test loss: 1.599717 acc: 0.670\n",
      "Epoch 187| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.182983 acc: 0.940\n",
      "test loss: 1.615767 acc: 0.667\n",
      "Epoch 188| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.185215 acc: 0.939\n",
      "test loss: 1.602710 acc: 0.666\n",
      "Epoch 189| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.175990 acc: 0.944\n",
      "test loss: 1.639165 acc: 0.665\n",
      "Epoch 190| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.178284 acc: 0.942\n",
      "test loss: 1.620982 acc: 0.664\n",
      "Epoch 191| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.177728 acc: 0.942\n",
      "test loss: 1.634499 acc: 0.666\n",
      "Epoch 192| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.177179 acc: 0.943\n",
      "test loss: 1.637045 acc: 0.672\n",
      "Epoch 193| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.176734 acc: 0.942\n",
      "test loss: 1.631232 acc: 0.665\n",
      "Epoch 194| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.175831 acc: 0.943\n",
      "test loss: 1.657987 acc: 0.665\n",
      "Epoch 195| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.171476 acc: 0.945\n",
      "test loss: 1.645042 acc: 0.666\n",
      "Epoch 196| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.171451 acc: 0.944\n",
      "test loss: 1.632193 acc: 0.670\n",
      "Epoch 197| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.169909 acc: 0.945\n",
      "test loss: 1.636129 acc: 0.668\n",
      "Epoch 198| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.169785 acc: 0.944\n",
      "test loss: 1.636553 acc: 0.671\n",
      "Epoch 199| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.165945 acc: 0.947\n",
      "test loss: 1.655216 acc: 0.667\n",
      "Epoch 200| 200 training complete!\n",
      "------------------------------\n",
      "train loss: 0.163648 acc: 0.947\n",
      "test loss: 1.659908 acc: 0.667\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, optimizer, loss_fun, num_epoches= epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_dataloader:\n",
    "    image, label = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40, 63, 93, 27, 17, 30, 81, 65, 64, 61, 57, 56, 29, 93, 27, 60, 91, 32,\n",
       "        45, 89, 28, 81, 76, 76, 47,  4, 15, 27, 49, 43, 36, 65, 37, 88, 62, 93,\n",
       "        63, 29, 10, 14, 79, 22, 89, 84, 51, 88, 15, 93, 19, 38, 79, 56, 92, 88,\n",
       "        82,  2, 75, 16, 26, 73, 27, 35, 18, 83, 86, 55, 28, 66, 80, 99, 72,  6,\n",
       "         7, 48, 12, 80, 90, 21, 60, 53, 41, 14, 31, 87, 77, 83, 69, 32, 81,  3,\n",
       "        81, 74, 15, 90, 48, 65,  6, 99, 18, 62])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
